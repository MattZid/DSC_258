{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a513cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import dateutil.parser\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f57c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1(dataset):\n",
    "    ratings = [d['rating'] for d in dataset]\n",
    "    lengths = [len(d['review_text']) for d in dataset]\n",
    "    print(\"first record of lengths: \"+  str(lengths[0]))\n",
    "    print(\"longest length review: \" +  str(max(lengths)))\n",
    "    \n",
    "    lengths_norm = [word/max(lengths) for word in lengths]\n",
    "    X_norm = np.array([[1,l] for l in lengths_norm]) # Note the inclusion of the constant term\n",
    "    y = np.array(ratings).T\n",
    "    model = sk.linear_model.LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_norm, y)\n",
    "    \n",
    "    theta = model.coef_\n",
    "    \n",
    "    y_pred = model.predict(X_norm)\n",
    "    sse = sum(x**2 for x in (y-y_pred))\n",
    "    mse = sse/len(y)\n",
    "    return theta, mse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74b8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q2(dataset):\n",
    "\n",
    "    day_of_week = []\n",
    "    month_list = []\n",
    "\n",
    "    ratings = [d['rating'] for d in dataset]\n",
    "    lengths = [len(d['review_text']) for d in dataset]\n",
    "    print(\"first record of lengths: \"+  str(lengths[0]))\n",
    "    print(\"longest length review: \" +  str(max(lengths)))\n",
    "    \n",
    "    lengths_norm = [word/max(lengths) for word in lengths]\n",
    "    X_norm = np.array([[1,l] for l in lengths_norm]) # Note the inclusion of the constant term\n",
    "    y = np.array(ratings).T\n",
    "\n",
    "    for d in dataset:\n",
    "        dow = str(d['date_added']).split(' ')[0]    \n",
    "        t = dateutil.parser.parse(d['date_added'])\n",
    "    \n",
    "        month_list.append(t.month)\n",
    "        day_of_week.append(dow)\n",
    "        \n",
    "    month_arr = np.array(month_list).reshape(-1,1)\n",
    "    dow_arr = np.array(day_of_week).reshape(-1,1)\n",
    "\n",
    "    unique_days = np.unique(dow_arr)\n",
    "    baseline = unique_days[0]\n",
    "    unique_days_reduced = unique_days[1:,]\n",
    "    print(baseline)\n",
    "    print(unique_days_reduced)\n",
    "    print(\"Number of Unique Days: \" + str(len(unique_days)))\n",
    "    print(\"Dimensions of Hot Encoded DOW feature: \" + str(len(unique_days_reduced)))\n",
    "    print(dow_arr.shape)\n",
    "    dow_arr = np.reshape(dow_arr,(-1))\n",
    "\n",
    "    dow_hot_encode = (dow_arr[:,None] == unique_days_reduced).astype(int)\n",
    "    X_norm = np.hstack((X_norm,dow_hot_encode))\n",
    "\n",
    "\n",
    "    unique_mo = np.unique(month_arr)\n",
    "    baseline_m = unique_mo[0]\n",
    "    unique_mo_reduced = unique_mo[1:,]\n",
    "    print(baseline_m)\n",
    "    print(unique_mo_reduced)\n",
    "    print(\"Number of Unique Months: \" + str(len(unique_mo)))\n",
    "    print(\"Dimensions of Hot Encoded DOW feature: \" + str(len(unique_mo_reduced)))\n",
    "    print(month_arr.shape)\n",
    "    month_arr = np.reshape(month_arr,(-1))\n",
    "\n",
    "    mo_hot_encode = (month_arr[:,None] == unique_mo_reduced).astype(int)\n",
    "    X_norm = np.hstack((X_norm,mo_hot_encode))\n",
    "\n",
    "    model = sk.linear_model.LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_norm, y)\n",
    "    theta = model.coef_\n",
    "\n",
    "    y_pred = model.predict(X_norm)\n",
    "    sse = sum(x**2 for x in (y-y_pred))\n",
    "    mse = sse/len(y)\n",
    "    return X_norm,y,mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac29a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q3(dataset):\n",
    "    day_of_week = []\n",
    "    weekday_num = []\n",
    "    month_list = []\n",
    "    month_num = []\n",
    "\n",
    "    ratings = [d['rating'] for d in dataset]\n",
    "    lengths = [len(d['review_text']) for d in dataset]\n",
    "\n",
    "    for d in dataset:\n",
    "        dow = str(d['date_added']).split(' ')[0]    \n",
    "        t = dateutil.parser.parse(d['date_added'])\n",
    "\n",
    "        month_list.append(t.month)\n",
    "        day_of_week.append(dow)\n",
    "        weekday_num.append(t.weekday())\n",
    "        month_num.append(t.month)\n",
    "\n",
    "    print(\"first record of lengths: \"+  str(lengths[0]))\n",
    "    print(\"longest length review: \" +  str(max(lengths)))\n",
    "    weekday_num = np.array(weekday_num).reshape(-1,1)\n",
    "    month_num = np.array(month_num).reshape(-1,1)\n",
    "\n",
    "    X_norm = np.array([[1,l] for l in lengths]) # Note the inclusion of the constant term\n",
    "    X_norm = np.hstack((X_norm,weekday_num))\n",
    "    X_norm = np.hstack((X_norm,month_num))\n",
    "    y = np.array(ratings).T\n",
    "\n",
    "    model = sk.linear_model.LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_norm, y)\n",
    "    theta = model.coef_\n",
    "\n",
    "    y_pred = model.predict(X_norm)\n",
    "    sse = sum(x**2 for x in (y-y_pred))\n",
    "    mse1 = sse/len(y)\n",
    "\n",
    "    return X_norm,y,mse1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8101ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q4(dataset):\n",
    "    dataset4 = dataset[:]\n",
    "    random.seed(0)\n",
    "    random.shuffle(dataset4)\n",
    "    cut = int(len(dataset4)/2)\n",
    "    end = int(len(dataset4))\n",
    "    dataset_train = dataset4[0:cut]\n",
    "    dataset_test = dataset4[cut:end]\n",
    "\n",
    "    print(\"Training Set Results:\")\n",
    "    Q2(dataset_train)\n",
    "    print(\"Test Set Results:\")\n",
    "    \n",
    "    ### data processing\n",
    "    day_of_week = []\n",
    "    month_list = []\n",
    "\n",
    "    ratings = [d['rating'] for d in dataset]\n",
    "    lengths = [len(d['review_text']) for d in dataset]\n",
    "    print(\"first record of lengths: \"+  str(lengths[0]))\n",
    "    print(\"longest length review: \" +  str(max(lengths)))\n",
    "    \n",
    "    lengths_norm = [word/max(lengths) for word in lengths]\n",
    "    X_norm = np.array([[1,l] for l in lengths_norm]) # Note the inclusion of the constant term\n",
    "    y = np.array(ratings).T\n",
    "\n",
    "    for d in dataset:\n",
    "        dow = str(d['date_added']).split(' ')[0]    \n",
    "        t = dateutil.parser.parse(d['date_added'])\n",
    "    \n",
    "        month_list.append(t.month)\n",
    "        day_of_week.append(dow)\n",
    "        \n",
    "    month_arr = np.array(month_list).reshape(-1,1)\n",
    "    dow_arr = np.array(day_of_week).reshape(-1,1)\n",
    "\n",
    "    unique_days = np.unique(dow_arr)\n",
    "    baseline = unique_days[0]\n",
    "    unique_days_reduced = unique_days[1:,]\n",
    "    print(baseline)\n",
    "    print(unique_days_reduced)\n",
    "    print(\"Number of Unique Days: \" + str(len(unique_days)))\n",
    "    print(\"Dimensions of Hot Encoded DOW feature: \" + str(len(unique_days_reduced)))\n",
    "    print(dow_arr.shape)\n",
    "    dow_arr = np.reshape(dow_arr,(-1))\n",
    "\n",
    "    dow_hot_encode = (dow_arr[:,None] == unique_days_reduced).astype(int)\n",
    "    X_norm = np.hstack((X_norm,dow_hot_encode))\n",
    "\n",
    "\n",
    "    unique_mo = np.unique(month_arr)\n",
    "    baseline_m = unique_mo[0]\n",
    "    unique_mo_reduced = unique_mo[1:,]\n",
    "    print(baseline_m)\n",
    "    print(unique_mo_reduced)\n",
    "    print(\"Number of Unique Months: \" + str(len(unique_mo)))\n",
    "    print(\"Dimensions of Hot Encoded DOW feature: \" + str(len(unique_mo_reduced)))\n",
    "    print(month_arr.shape)\n",
    "    month_arr = np.reshape(month_arr,(-1))\n",
    "\n",
    "    mo_hot_encode = (month_arr[:,None] == unique_mo_reduced).astype(int)\n",
    "    X_norm = np.hstack((X_norm,mo_hot_encode))\n",
    "\n",
    "    y_pred = model.predict(X_norm)\n",
    "    sse = sum(x**2 for x in (y-y_pred))\n",
    "    mse = sse/len(y)\n",
    "    print(\"test mse:\")\n",
    "    return mse\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81829160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_hotcode(dataset):\n",
    "    day_of_week = []\n",
    "    month_list = []\n",
    "\n",
    "    ratings = [d['rating'] for d in dataset]\n",
    "    lengths = [len(d['review_text']) for d in dataset]\n",
    "    print(\"first record of lengths: \"+  str(lengths[0]))\n",
    "    print(\"longest length review: \" +  str(max(lengths)))\n",
    "    \n",
    "    lengths_norm = [word/max(lengths) for word in lengths]\n",
    "    X_norm = np.array([[1,l] for l in lengths_norm]) # Note the inclusion of the constant term\n",
    "    y = np.array(ratings).T\n",
    "\n",
    "    for d in dataset:\n",
    "        dow = str(d['date_added']).split(' ')[0]    \n",
    "        t = dateutil.parser.parse(d['date_added'])\n",
    "    \n",
    "        month_list.append(t.month)\n",
    "        day_of_week.append(dow)\n",
    "        \n",
    "    month_arr = np.array(month_list).reshape(-1,1)\n",
    "    dow_arr = np.array(day_of_week).reshape(-1,1)\n",
    "\n",
    "    unique_days = np.unique(dow_arr)\n",
    "    baseline = unique_days[0]\n",
    "    unique_days_reduced = unique_days[1:,]\n",
    "    print(baseline)\n",
    "    print(unique_days_reduced)\n",
    "    print(\"Number of Unique Days: \" + str(len(unique_days)))\n",
    "    print(\"Dimensions of Hot Encoded DOW feature: \" + str(len(unique_days_reduced)))\n",
    "    print(dow_arr.shape)\n",
    "    dow_arr = np.reshape(dow_arr,(-1))\n",
    "\n",
    "    dow_hot_encode = (dow_arr[:,None] == unique_days_reduced).astype(int)\n",
    "    X_norm = np.hstack((X_norm,dow_hot_encode))\n",
    "\n",
    "\n",
    "    unique_mo = np.unique(month_arr)\n",
    "    baseline_m = unique_mo[0]\n",
    "    unique_mo_reduced = unique_mo[1:,]\n",
    "    print(baseline_m)\n",
    "    print(unique_mo_reduced)\n",
    "    print(\"Number of Unique Months: \" + str(len(unique_mo)))\n",
    "    print(\"Dimensions of Hot Encoded DOW feature: \" + str(len(unique_mo_reduced)))\n",
    "    print(month_arr.shape)\n",
    "    month_arr = np.reshape(month_arr,(-1))\n",
    "\n",
    "    mo_hot_encode = (month_arr[:,None] == unique_mo_reduced).astype(int)\n",
    "    X_norm = np.hstack((X_norm,mo_hot_encode))\n",
    "    return X_norm,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20174162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_std(dataset): \n",
    "    day_of_week = []\n",
    "    weekday_num = []\n",
    "    month_list = []\n",
    "    month_num = []\n",
    "\n",
    "    ratings = [d['rating'] for d in dataset]\n",
    "    lengths = [len(d['review_text']) for d in dataset]\n",
    "\n",
    "    for d in dataset:\n",
    "        dow = str(d['date_added']).split(' ')[0]    \n",
    "        t = dateutil.parser.parse(d['date_added'])\n",
    "\n",
    "        month_list.append(t.month)\n",
    "        day_of_week.append(dow)\n",
    "        weekday_num.append(t.weekday())\n",
    "        month_num.append(t.month)\n",
    "\n",
    "    print(\"first record of lengths: \"+  str(lengths[0]))\n",
    "    print(\"longest length review: \" +  str(max(lengths)))\n",
    "    weekday_num = np.array(weekday_num).reshape(-1,1)\n",
    "    month_num = np.array(month_num).reshape(-1,1)\n",
    "\n",
    "    X_norm = np.array([[1,l] for l in lengths]) # Note the inclusion of the constant term\n",
    "    X_norm = np.hstack((X_norm,weekday_num))\n",
    "    X_norm = np.hstack((X_norm,month_num))\n",
    "    y = np.array(ratings).T\n",
    "    return X_norm,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f35b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q4(dataset):\n",
    "    dataset4 = dataset[:]\n",
    "    random.seed(0)\n",
    "    random.shuffle(dataset4)\n",
    "    cut = int(len(dataset4)/2)\n",
    "    end = int(len(dataset4))\n",
    "    dataset_train = dataset4[0:cut]\n",
    "    dataset_test = dataset4[cut:end]\n",
    "\n",
    "    print(\"Processing Training Data Hot Encode:\")    \n",
    "    print()\n",
    "    X_norm,y = processing_hotcode(dataset_test)\n",
    "\n",
    "    model = sk.linear_model.LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_norm, y)\n",
    "    theta = model.coef_\n",
    "\n",
    "    X_norm_test, y_test = processing_hotcode(dataset_test)\n",
    "   \n",
    "    y_pred = model.predict(X_norm_test)\n",
    "    sse = sum(x**2 for x in (y_test-y_pred))\n",
    "    mse1 = sse/len(y_test)\n",
    "    print(\"test mse:\")\n",
    "\n",
    "    X_norm, y = processing_std(dataset_train)\n",
    "    model = sk.linear_model.LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_norm, y)\n",
    "    theta = model.coef_\n",
    "\n",
    "    X_norm_test, y_test = processing_std(dataset_test)\n",
    "    y_pred = model.predict(X_norm_test)\n",
    "    sse = sum(x**2 for x in (y_test-y_pred))\n",
    "    mse2 = sse/len(y_test)\n",
    "    print(\"test mse2:\")\n",
    "    \n",
    "    return mse1, mse2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83216af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureQ5(dataset):\n",
    "    X = [[1, len(d['review/text'])] for d in dataset]\n",
    "    y = [d['review/overall'] >= 4 for d in dataset]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4839e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureQ5(dataset):\n",
    "    X = [[1, len(d['review/text'])] for d in dataset]\n",
    "    \n",
    "    y = [d['review/overall'] >= 4 for d in dataset]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175126b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q5(dataset, feature_fn):\n",
    "    X, y = feature_fn(dataset)\n",
    "\n",
    "    mod = sk.linear_model.LogisticRegression(class_weight='balanced')\n",
    "    mod.fit(X,y)\n",
    "    predictions = mod.predict(X)\n",
    "    correct = predictions == y\n",
    "    sum(correct) / len(correct)\n",
    "\n",
    "    TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "    FP = sum([(p and not l) for (p,l) in zip(predictions, y)])\n",
    "    TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "    FN = sum([(not p and l) for (p,l) in zip(predictions, y)])\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "\n",
    "    BER = 1 - 1/2 * (TPR + TNR)\n",
    "    BER\n",
    "    return TP, TN, FP, FN, BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00214813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q5_Q6(dataset, feature_fn):\n",
    "    X, y = feature_fn(dataset)\n",
    "\n",
    "    mod = sk.linear_model.LogisticRegression(class_weight='balanced')\n",
    "    mod.fit(X,y)\n",
    "    predictions = mod.predict(X)\n",
    "    correct = predictions == y\n",
    "    sum(correct) / len(correct)\n",
    "\n",
    "    TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "    FP = sum([(p and not l) for (p,l) in zip(predictions, y)])\n",
    "    TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "    FN = sum([(not p and l) for (p,l) in zip(predictions, y)])\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "\n",
    "    BER = 1 - 1/2 * (TPR + TNR)\n",
    "    BER\n",
    "    return predictions, y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ae40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q6(dataset):\n",
    "    predictions, y = Q5_Q6(dataset, featureQ5)\n",
    "    precisions = []\n",
    "\n",
    "    k_values = [1, 100, 1000, 10000]\n",
    "    for k in k_values:\n",
    "        if k == 1:\n",
    "            TPR_k = 1.0 if (predictions[0] and y[0]) else 0.0\n",
    "        else:\n",
    "            preds_k = predictions[0:k]\n",
    "            y_k = y[0:k]\n",
    "            TP_k = sum([(p and l) for (p,l) in zip(preds_k, y_k)])\n",
    "            FP_k = sum([(p and not l) for (p,l) in zip(preds_k, y_k)])\n",
    "            TPR_k = float(TP_k / k)\n",
    "        precisions.append(TPR_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
