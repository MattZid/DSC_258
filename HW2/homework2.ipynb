{"cells": [{"cell_type": "code", "execution_count": 1, "id": "07ad6b17", "metadata": {}, "outputs": [], "source": ["from collections import defaultdict\n", "from sklearn import linear_model\n", "import numpy\n", "import math"]}, {"cell_type": "code", "execution_count": null, "id": "074d759b", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "81325322", "metadata": {}, "outputs": [], "source": ["def feat(d, catID, maxLength, includeCat = True, includeReview = True, includeLength = True):\n", "    feat = []\n", "\n", "    if includeCat:\n", "        # Drop one category to avoid redundancy with the intercept term\n", "        num_cats = len(catID)\n", "        cat_features = [0.0] * max(num_cats - 1, 0)\n", "        if num_cats > 1:\n", "            category = d.get('beer/style')\n", "            if category in catID:\n", "                idx = catID[category]\n", "                if idx > 0:\n", "                    cat_features[idx - 1] = 1.0\n", "        feat.extend(cat_features)\n", "\n", "    if includeReview:\n", "        review_keys = [\n", "            'review/appearance',\n", "            'review/aroma',\n", "            'review/palate',\n", "            'review/taste',\n", "            'review/overall'\n", "        ]\n", "        feat.extend(float(d.get(key, 0.0)) for key in review_keys)\n", "\n", "    if includeLength:\n", "        text = d.get('review/text', '')\n", "        length = len(text) if isinstance(text, str) else 0\n", "        feat.append((length / maxLength) if maxLength else 0.0)\n", "\n", "    return feat + [1]\n"]}, {"cell_type": "code", "execution_count": null, "id": "d5ada384", "metadata": {}, "outputs": [], "source": ["def pipeline(reg, catID, dataTrain, dataValid, dataTest, includeCat=True, includeReview=True, includeLength=True):\n", "    mod = linear_model.LogisticRegression(C=reg, class_weight='balanced')\n", "\n", "    maxLength = max([len(d['review/text']) for d in dataTrain])\n", "    \n", "    Xtrain = [feat(d, catID, maxLength, includeCat, includeReview, includeLength) for d in dataTrain]\n", "    Xvalid = [feat(d, catID, maxLength, includeCat, includeReview, includeLength) for d in dataValid]\n", "    Xtest = [feat(d, catID, maxLength, includeCat, includeReview, includeLength) for d in dataTest]\n", "    \n", "    yTrain = numpy.array([d['beer/ABV'] > 7 for d in dataTrain], dtype=int)\n", "    yValid = numpy.array([d['beer/ABV'] > 7 for d in dataValid], dtype=int)\n", "    yTest = numpy.array([d['beer/ABV'] > 7 for d in dataTest], dtype=int)\n", "    \n", "    # (1) Fit the model on the training set\n", "    mod.fit(Xtrain, yTrain)\n", "\n", "    def balanced_error_rate(y_true, y_pred):\n", "        y_true = numpy.asarray(y_true, dtype=int)\n", "        y_pred = numpy.asarray(y_pred, dtype=int)\n", "        positives = (y_true == 1)\n", "        negatives = (y_true == 0)\n", "        pos_count = positives.sum()\n", "        neg_count = negatives.sum()\n", "        tpr = ((y_pred[positives] == 1).sum() / pos_count) if pos_count else 0.0\n", "        tnr = ((y_pred[negatives] == 0).sum() / neg_count) if neg_count else 0.0\n", "        return 1 - 0.5 * (tpr + tnr)\n", "\n", "    # (2) Compute validation BER\n", "    yValidPred = mod.predict(Xvalid)\n", "    vBER = balanced_error_rate(yValid, yValidPred)\n", "\n", "    # (3) Compute test BER\n", "    yTestPred = mod.predict(Xtest)\n", "    tBER = balanced_error_rate(yTest, yTestPred)\n", "\n", "    return mod, vBER, tBER\n"]}, {"cell_type": "code", "execution_count": null, "id": "6460933e", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 2, "id": "08711296", "metadata": {}, "outputs": [], "source": ["### Question 1"]}, {"cell_type": "code", "execution_count": null, "id": "f872f9ec", "metadata": {}, "outputs": [], "source": ["def Q1(catID, dataTrain, dataValid, dataTest):\n", "    # No need to modify this if you've implemented the functions above\n", "    mod, validBER, testBER = pipeline(10, catID, dataTrain, dataValid, dataTest, True, False, False)\n", "    return mod, validBER, testBER"]}, {"cell_type": "code", "execution_count": null, "id": "e84af258", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 3, "id": "cf88be81", "metadata": {}, "outputs": [], "source": ["### Question 2"]}, {"cell_type": "code", "execution_count": null, "id": "2bd1768d", "metadata": {}, "outputs": [], "source": ["def Q2(catID, dataTrain, dataValid, dataTest):\n", "    mod, validBER, testBER = pipeline(10, catID, dataTrain, dataValid, dataTest, True, True, True)\n", "    return mod, validBER, testBER"]}, {"cell_type": "code", "execution_count": null, "id": "baf7adad", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "eda7330e", "metadata": {}, "outputs": [], "source": ["### Question 3"]}, {"cell_type": "code", "execution_count": null, "id": "f8985755", "metadata": {}, "outputs": [], "source": ["def Q3(catID, dataTrain, dataValid, dataTest):\n", "    bestModel = None\n", "    bestValidBER = None\n", "    bestTestBER = None\n", "\n", "    for C in [0.001, 0.01, 0.1, 1, 10]:\n", "        mod, validBER, testBER = pipeline(C, catID, dataTrain, dataValid, dataTest, True, True, True)\n", "        if bestValidBER is None or validBER < bestValidBER:\n", "            bestModel = mod\n", "            bestValidBER = validBER\n", "            bestTestBER = testBER\n", "\n", "    return bestModel, bestValidBER, bestTestBER\n"]}, {"cell_type": "code", "execution_count": null, "id": "da52688b", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 4, "id": "af37382b", "metadata": {}, "outputs": [], "source": ["### Question 4"]}, {"cell_type": "code", "execution_count": 11, "id": "c66382ad", "metadata": {}, "outputs": [], "source": ["def Q4(C, catID, dataTrain, dataValid, dataTest):\n", "    mod, validBER, testBER_noCat = pipeline(C, catID, dataTrain, dataValid, dataTest, False, True, True)\n", "    mod, validBER, testBER_noReview = pipeline(C, catID, dataTrain, dataValid, dataTest, True, False, True)\n", "    mod, validBER, testBER_noLength = pipeline(C, catID, dataTrain, dataValid, dataTest, True, True, False)\n", "    return testBER_noCat, testBER_noReview, testBER_noLength"]}, {"cell_type": "code", "execution_count": null, "id": "a6b763d8", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "4dbd21ee", "metadata": {}, "outputs": [], "source": ["### Question 5"]}, {"cell_type": "code", "execution_count": null, "id": "024a628f", "metadata": {}, "outputs": [], "source": ["def Jaccard(s1, s2):\n", "    # Implement"]}, {"cell_type": "code", "execution_count": null, "id": "94773001", "metadata": {}, "outputs": [], "source": ["def mostSimilar(i, N, usersPerItem):\n", "    # Implement...\n", "\n", "    # Should be a list of (similarity, itemID) pairs\n", "    return similarities[:N]"]}, {"cell_type": "code", "execution_count": null, "id": "ed66772f", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 7, "id": "0d18b14a", "metadata": {}, "outputs": [], "source": ["### Question 6"]}, {"cell_type": "code", "execution_count": 8, "id": "71fc4d5c", "metadata": {}, "outputs": [], "source": ["def MSE(y, ypred):\n", "    # Implement..."]}, {"cell_type": "code", "execution_count": null, "id": "cf535d86", "metadata": {}, "outputs": [], "source": ["def getMeanRating(dataTrain):\n", "    # Implement...\n", "\n", "def getUserAverages(itemsPerUser, ratingDict):\n", "    # Implement (should return a dictionary mapping users to their averages)\n", "    return userAverages\n", "\n", "def getItemAverages(usersPerItem, ratingDict):\n", "    # Implement...\n", "    return itemAverages"]}, {"cell_type": "code", "execution_count": null, "id": "929248fb", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 9, "id": "df9fa7b4", "metadata": {}, "outputs": [], "source": ["def predictRating(user,item,ratingMean,reviewsPerUser,usersPerItem,itemsPerUser,userAverages,itemAverages):\n", "    # Solution for Q6, should return a rating\n", "    return 0"]}, {"cell_type": "code", "execution_count": null, "id": "d608092c", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 10, "id": "7afad6f5", "metadata": {}, "outputs": [], "source": ["### Question 7"]}, {"cell_type": "code", "execution_count": null, "id": "21b64e0f", "metadata": {}, "outputs": [], "source": ["def predictRatingQ7(user,item,ratingMean,reviewsPerUser,usersPerItem,itemsPerUser,userAverages,itemAverages):\n", "    # Your solution here\n", "    return 0"]}, {"cell_type": "code", "execution_count": null, "id": "81f4384a", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.2"}}, "nbformat": 4, "nbformat_minor": 5}